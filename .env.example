DB_PASSWORD=changeme
SECRET_KEY=dev-secret-key-change-in-production-use-openssl-rand-hex-32

# Background workers
ENABLE_DIRECTORY_WATCHER=true
ENABLE_IMAP_WATCHER=false

# Embeddings Configuration
# Set EMBEDDING_ENABLED=true to enable automatic embedding generation
EMBEDDING_ENABLED=true

# Choose embedding provider: "local", "openai", or "ollama"
# - local: Uses sentence-transformers (requires ~500MB RAM, slower but free, needs PyTorch)
# - openai: Uses OpenAI API (fast, low memory, requires API key and costs money)
# - ollama: Uses Ollama (free, requires Ollama running, uses LLM_BASE_URL)
EMBEDDING_PROVIDER=ollama

# Model selection (must match provider):
# For local: all-MiniLM-L6-v2 (384 dimensions)
# For OpenAI: text-embedding-3-small (1536 dimensions)
# For Ollama: nomic-embed-text (768 dimensions, recommended), mxbai-embed-large (1024 dimensions)
EMBEDDING_MODEL=nomic-embed-text

# Dimension must match model:
# 384 for all-MiniLM-L6-v2, 768 for nomic-embed-text, 1536 for text-embedding-3-small
EMBEDDING_DIMENSION=768

# OpenAI API Key (required if EMBEDDING_PROVIDER=openai or LLM_PROVIDER=openai)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# LLM Configuration (Phase 4 - Optional AI Metadata Extraction)
# Set LLM_ENABLED=true to enable automatic metadata extraction and auto-tagging
LLM_ENABLED=true

# Choose LLM provider: "openai", "gemini", or "ollama"
# - openai: Uses OpenAI API (fast, requires API key, uses OPENAI_API_KEY above)
# - gemini: Uses Google Gemini API (requires GEMINI_API_KEY below)
# - ollama: Uses local Ollama server (free, requires Ollama running locally)
LLM_PROVIDER=openai

# Model selection (must match provider):
# For OpenAI: gpt-4o-mini (fast, cheap), gpt-4o (more accurate, expensive)
# For Gemini: gemini-pro, gemini-1.5-flash
# For Ollama: llama2, mistral, llama3 (must be pulled first with `ollama pull`)
LLM_MODEL=gpt-4o-mini

# Gemini API Key (required only if LLM_PROVIDER=gemini)
# Get your key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=

# Ollama Base URL (required only if LLM_PROVIDER=ollama)
# Default is http://localhost:11434 if running Ollama locally
# LLM_BASE_URL=http://localhost:11434

# OIDC Configuration (Phase 7 - Optional Enterprise SSO)
OIDC_ENABLED=false
OIDC_DISCOVERY_URL=
OIDC_CLIENT_ID=
OIDC_CLIENT_SECRET=
OIDC_REDIRECT_URI=http://localhost:8080/auth/callback

# Vision OCR Configuration (Phase 2 - LLM-based text extraction)
# Uses Ollama with vision models instead of traditional OCR (PaddleOCR/EasyOCR)
# Note: Vision OCR uses the same LLM_BASE_URL setting as LLM metadata extraction
OCR_ENABLED=true

# Vision model for text extraction (requires Ollama with a vision-capable model)
# Recommended models: gemma3:4b-it-q4_K_M, llava, llava:13b
# Make sure to pull the model first: ollama pull gemma3:4b-it-q4_K_M
VISION_OCR_MODEL=minicpm-v
